# Implementation of methods seen in class and in the labs

def least_squares_GD(y, tx, initial_w, max_iters, gamma):
    # Linear regression using gradient descent
    return 0

def least_squares_SGD(y, tx, initial_w, max_iters, gamma):
    # Linear regression using stochastic gradient descent
    return 0

def least_squares(y, tx):
    # Least squares regression using normal equations
    return 0

def ridge_regression(y, tx, lambda_):
    # Ridge regression using normal equations
    return 0

def logistic_regression(y, tx, initial_w, max_iters, gamma):
    # Logistic regression using gradient descent or SGD
    return 0

def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):
    # Regularized logistic regression using gradient descent or SGD
    return 0
