{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from features_eng import *\n",
    "from plots import *\n",
    "from helpers import *\n",
    "from preprocessing import *\n",
    "from cross_validation import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER_BOUND = -1\n",
    "UPPER_BOUND = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"competition-data/\"\n",
    "DATA_TEST = \"test.csv\"\n",
    "DATA_TRAIN = \"train.csv\"\n",
    "y_train, tx_train, ids_train = load_csv_data(DATA_FOLDER + DATA_TRAIN, LOWER_BOUND, UPPER_BOUND)\n",
    "y_test, tx_test, ids_test = load_csv_data(DATA_FOLDER + DATA_TEST, LOWER_BOUND, UPPER_BOUND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inverse log values of features which are positive in value.\n",
    "inv_log_cols = [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 12, 13, 16, 19, 21, 23, 26]\n",
    "\n",
    "tx_train_inv_log_cols = np.log(1 / (1 + tx_train[:, inv_log_cols]))\n",
    "tx_train = np.hstack((tx_train, tx_train_inv_log_cols))\n",
    "\n",
    "tx_test_inv_log_cols = np.log(1 / (1 + tx_test[:, inv_log_cols]))\n",
    "tx_test = np.hstack((tx_test, tx_test_inv_log_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into 4 sets depending on the feature 22: 'PRI_jet_num' (categorical feature)\n",
    "masks_jet_train = get_jet_masks(tx_train)\n",
    "masks_jet_test = get_jet_masks(tx_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99913, 30)\n",
      "(99913, 1)\n"
     ]
    }
   ],
   "source": [
    "# Cross validate the different models one by one (change manually)\n",
    "model_nb = 0\n",
    "\n",
    "current_tx_train = tx_train[masks_jet_train[model_nb]]\n",
    "current_y_train = y_train[masks_jet_train[model_nb]]\n",
    "\n",
    "# Remove columns full of NaN\n",
    "current_tx_train = current_tx_train[:, ~np.all(np.isnan(current_tx_train), axis=0)]\n",
    "\n",
    "# Remove columns without standard deviation at all\n",
    "current_tx_train = current_tx_train[:, np.nanstd(current_tx_train, axis=0) != 0]\n",
    "\n",
    "# Replace remaining NaN by median\n",
    "current_tx_train = replace_nan_by_median(current_tx_train)\n",
    "\n",
    "# Standardize features\n",
    "mean_train, std_train, current_tx_train = standardize(current_tx_train)\n",
    "\n",
    "print(current_tx_train.shape)\n",
    "print(current_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,\n",
       " 50,\n",
       " 0,\n",
       " 0.00031622776601683794,\n",
       " 0.84472024822340119,\n",
       " array([[ -2.39793435e-01],\n",
       "        [  8.48354061e-02],\n",
       "        [ -1.23477961e-01],\n",
       "        [ -1.24908431e-02],\n",
       "        [ -9.15362397e-02],\n",
       "        [  4.81596483e-02],\n",
       "        [ -6.17161234e-03],\n",
       "        [  3.93828880e-04],\n",
       "        [ -1.29420016e-05],\n",
       "        [  1.74534864e-07],\n",
       "        [ -1.26692255e-01],\n",
       "        [  1.50429364e-01],\n",
       "        [  6.57151904e-02],\n",
       "        [ -4.40324507e-02],\n",
       "        [  1.08102601e-02],\n",
       "        [ -1.37292846e-03],\n",
       "        [  1.01023727e-04],\n",
       "        [ -4.11601952e-06],\n",
       "        [  7.08121221e-08],\n",
       "        [ -9.73627431e-02],\n",
       "        [ -9.75512887e-02],\n",
       "        [ -2.69050178e-03],\n",
       "        [  1.69155646e-02],\n",
       "        [  5.16938408e-02],\n",
       "        [ -9.13853777e-03],\n",
       "        [  7.22022624e-04],\n",
       "        [ -2.83726215e-05],\n",
       "        [  4.48920289e-07],\n",
       "        [  4.39574109e-02],\n",
       "        [ -3.14864105e-02],\n",
       "        [  3.35436618e-02],\n",
       "        [ -2.47853691e-02],\n",
       "        [ -2.68749679e-03],\n",
       "        [  2.97248604e-03],\n",
       "        [ -1.04346212e-03],\n",
       "        [  3.22053793e-04],\n",
       "        [ -3.82985710e-03],\n",
       "        [  2.91558488e-01],\n",
       "        [  8.68431636e-02],\n",
       "        [ -1.67125765e-01],\n",
       "        [ -2.84279882e-02],\n",
       "        [  9.09114948e-02],\n",
       "        [  2.68366147e-02],\n",
       "        [ -3.60576542e-02],\n",
       "        [  8.80302314e-03],\n",
       "        [ -6.92751729e-04],\n",
       "        [  4.39219154e-02],\n",
       "        [ -3.21693078e-02],\n",
       "        [  3.06313893e-02],\n",
       "        [  1.68822759e-02],\n",
       "        [ -2.84936556e-03],\n",
       "        [  3.11618790e-03],\n",
       "        [ -9.73094889e-04],\n",
       "        [ -3.58412409e-05],\n",
       "        [  3.81487826e-03],\n",
       "        [  8.76088378e-02],\n",
       "        [  8.39494949e-03],\n",
       "        [ -2.09865024e-02],\n",
       "        [ -8.38684784e-02],\n",
       "        [ -9.61544036e-03],\n",
       "        [  4.77778346e-04],\n",
       "        [  1.71083523e-06],\n",
       "        [ -5.22728818e-07],\n",
       "        [  9.10085895e-09],\n",
       "        [ -3.93440955e-02],\n",
       "        [ -1.16997933e-02],\n",
       "        [  5.54483568e-03],\n",
       "        [  4.28155578e-03],\n",
       "        [ -5.51349889e-03],\n",
       "        [ -1.04642032e-02],\n",
       "        [  1.29713271e-03],\n",
       "        [ -6.31241521e-05],\n",
       "        [  1.14983139e-06],\n",
       "        [  6.13128663e-02],\n",
       "        [ -1.13141807e-01],\n",
       "        [  5.59115301e-02],\n",
       "        [ -6.36843235e-02],\n",
       "        [  1.97993369e-02],\n",
       "        [ -9.25629636e-03],\n",
       "        [  4.33827151e-02],\n",
       "        [ -2.95395775e-02],\n",
       "        [  5.52031921e-03],\n",
       "        [  1.19646789e-01],\n",
       "        [  2.71402024e-02],\n",
       "        [  3.75213798e-03],\n",
       "        [ -3.23367709e-02],\n",
       "        [ -2.29644619e-02],\n",
       "        [  2.30328166e-03],\n",
       "        [ -1.11397965e-04],\n",
       "        [  2.92360459e-06],\n",
       "        [ -3.33183115e-08],\n",
       "        [ -7.16417237e-03],\n",
       "        [  6.96828098e-02],\n",
       "        [  2.91021134e-02],\n",
       "        [ -9.50809956e-02],\n",
       "        [ -1.99720653e-02],\n",
       "        [  3.58253064e-02],\n",
       "        [  4.10066656e-03],\n",
       "        [ -4.55006123e-03],\n",
       "        [ -1.52799911e-04],\n",
       "        [ -6.33239066e-05],\n",
       "        [ -2.78409200e-02],\n",
       "        [ -7.48368555e-03],\n",
       "        [  3.33512516e-02],\n",
       "        [ -1.16659872e-02],\n",
       "        [ -1.41978700e-02],\n",
       "        [  1.46764353e-02],\n",
       "        [  2.02001319e-03],\n",
       "        [ -3.40540777e-03],\n",
       "        [  1.56931386e-02],\n",
       "        [ -3.75715142e-02],\n",
       "        [ -1.12434012e-02],\n",
       "        [  3.50030413e-02],\n",
       "        [ -1.12931223e-01],\n",
       "        [  1.46179303e-02],\n",
       "        [ -8.83071074e-04],\n",
       "        [  2.71959916e-05],\n",
       "        [ -3.43090943e-07],\n",
       "        [  1.10868161e-02],\n",
       "        [ -1.14052312e-02],\n",
       "        [ -6.47354859e-03],\n",
       "        [ -5.16719869e-02],\n",
       "        [  3.85942308e-03],\n",
       "        [  2.51882500e-02],\n",
       "        [ -1.89268186e-03],\n",
       "        [ -3.77426252e-03],\n",
       "        [  3.37027664e-04],\n",
       "        [ -8.15010900e-03],\n",
       "        [ -9.64455704e-03],\n",
       "        [  2.95081258e-02],\n",
       "        [  2.08781986e-02],\n",
       "        [ -4.03073811e-02],\n",
       "        [ -1.47784101e-02],\n",
       "        [  2.07403234e-02],\n",
       "        [  3.04941216e-03],\n",
       "        [ -3.49409509e-03],\n",
       "        [  7.00788746e-04],\n",
       "        [ -3.16903451e-02],\n",
       "        [ -7.09676143e-02],\n",
       "        [  5.59610483e-03],\n",
       "        [ -1.41187125e-03],\n",
       "        [  2.97335481e-04],\n",
       "        [ -3.03062452e-05],\n",
       "        [  1.50754159e-06],\n",
       "        [ -2.97094046e-08],\n",
       "        [ -8.53571843e-04],\n",
       "        [ -4.12566557e-02],\n",
       "        [ -7.01693197e-03],\n",
       "        [  6.09196357e-02],\n",
       "        [ -6.85525272e-03],\n",
       "        [ -2.45247459e-02],\n",
       "        [  7.08736215e-03],\n",
       "        [  2.71744556e-03],\n",
       "        [ -1.33579074e-03],\n",
       "        [  3.99692453e-02],\n",
       "        [  6.40396815e-03],\n",
       "        [ -9.25555087e-03],\n",
       "        [ -1.19977946e-02],\n",
       "        [ -3.71435370e-02],\n",
       "        [  9.89493284e-03],\n",
       "        [ -1.30109049e-03],\n",
       "        [  9.03659361e-05],\n",
       "        [ -2.59171460e-06],\n",
       "        [ -8.26769404e-02],\n",
       "        [ -1.21563399e-01],\n",
       "        [  1.29272573e-01],\n",
       "        [  8.83964412e-02],\n",
       "        [ -3.85350599e-02],\n",
       "        [ -4.04279960e-03],\n",
       "        [  3.83577310e-03],\n",
       "        [ -6.11606729e-04],\n",
       "        [  3.09100322e-05],\n",
       "        [  1.71241441e-01],\n",
       "        [ -1.95273531e-02],\n",
       "        [  2.33294583e-03],\n",
       "        [  7.96706633e-02],\n",
       "        [ -2.64570247e-02],\n",
       "        [ -2.25033636e-02],\n",
       "        [  1.50480228e-02],\n",
       "        [ -3.16942325e-03],\n",
       "        [  2.29954629e-04],\n",
       "        [  1.33493359e-01],\n",
       "        [ -1.48393717e-01],\n",
       "        [  1.45297080e-01],\n",
       "        [  8.23351928e-02],\n",
       "        [ -4.53876886e-02],\n",
       "        [ -2.02685089e-02],\n",
       "        [  1.61675010e-02],\n",
       "        [ -3.40044066e-03],\n",
       "        [  2.35346345e-04],\n",
       "        [  3.32149958e-02],\n",
       "        [ -6.03688926e-02],\n",
       "        [  6.84691522e-02],\n",
       "        [  2.14669760e-02],\n",
       "        [ -6.98393849e-02],\n",
       "        [  4.38783531e-03],\n",
       "        [  2.32036883e-02],\n",
       "        [ -8.07620797e-03],\n",
       "        [ -1.62453684e-03],\n",
       "        [ -2.21691723e-01],\n",
       "        [  1.35553670e-01],\n",
       "        [  6.72398371e-02],\n",
       "        [ -7.73179815e-02],\n",
       "        [ -2.57347189e-02],\n",
       "        [ -6.68901276e-02],\n",
       "        [ -1.06742121e-02],\n",
       "        [  7.00883169e-03],\n",
       "        [ -6.54234411e-04],\n",
       "        [  3.32957089e-02],\n",
       "        [ -6.10477103e-02],\n",
       "        [  6.85125478e-02],\n",
       "        [  2.19384680e-02],\n",
       "        [ -6.96757700e-02],\n",
       "        [  5.10555988e-03],\n",
       "        [  2.43825921e-02],\n",
       "        [  4.31300256e-04],\n",
       "        [ -1.93096716e-03],\n",
       "        [ -7.08812102e-02],\n",
       "        [  4.62997682e-02],\n",
       "        [  2.84657277e-02],\n",
       "        [ -4.10164970e-02],\n",
       "        [ -2.45780447e-02],\n",
       "        [  1.79752655e-02],\n",
       "        [  1.26409774e-03],\n",
       "        [ -4.58163528e-05],\n",
       "        [ -1.43973371e-04],\n",
       "        [  6.78211551e-02],\n",
       "        [ -2.44437539e-02],\n",
       "        [  2.37039100e-03],\n",
       "        [  3.52824901e-03],\n",
       "        [ -7.21546301e-03],\n",
       "        [  1.41488570e-03],\n",
       "        [ -2.37269418e-03],\n",
       "        [  1.96013392e-03],\n",
       "        [ -3.63689527e-04],\n",
       "        [ -9.69415108e-02],\n",
       "        [  8.69968826e-02],\n",
       "        [ -5.66914557e-02],\n",
       "        [  3.68136566e-04],\n",
       "        [  4.84741562e-02],\n",
       "        [  1.65289219e-02],\n",
       "        [ -1.41038816e-02],\n",
       "        [ -5.18553239e-03],\n",
       "        [ -9.70981187e-04],\n",
       "        [  1.23712541e-02],\n",
       "        [ -4.32080152e-02],\n",
       "        [  4.01032297e-02],\n",
       "        [ -1.38147417e-02],\n",
       "        [ -7.37570061e-02],\n",
       "        [  5.30741073e-03],\n",
       "        [  2.64969769e-03],\n",
       "        [  5.91968135e-03],\n",
       "        [  2.66301754e-04],\n",
       "        [  5.34624945e-02],\n",
       "        [ -4.91814772e-02],\n",
       "        [  3.30741180e-02],\n",
       "        [  3.44965031e-02],\n",
       "        [ -4.27669990e-02],\n",
       "        [  1.41617712e-02],\n",
       "        [ -1.42123626e-03],\n",
       "        [ -8.86587747e-05],\n",
       "        [  1.69705229e-05],\n",
       "        [  1.21164058e-02],\n",
       "        [  9.42962992e-03],\n",
       "        [ -1.97532615e-02],\n",
       "        [ -3.66790048e-02],\n",
       "        [ -1.19551572e-02],\n",
       "        [  2.86529965e-02],\n",
       "        [ -1.28992150e-02],\n",
       "        [  2.40374031e-03],\n",
       "        [ -1.62360393e-04]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"ridge_regression\"\n",
    "degrees = np.arange(7, 13, 1)\n",
    "lambdas = np.logspace(-5, -2, 7)\n",
    "results = cross_validation_demo(current_y_train, current_tx_train, model=model, degrees=degrees, lambdas=lambdas)\n",
    "results.sort(key=lambda x: -x[4])\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAFJCAYAAAA2SkIQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115621dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_ridge_performance(results, degrees, lambdas, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting things together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of split 0: 0.844985137069\n",
      "Accuracy of split 1: 0.809604869493\n",
      "Accuracy of split 2: 0.839079775303\n",
      "Accuracy of split 3: 0.845425013535\n",
      "Number of 1: 178027\n",
      "Number of -1: 390211\n"
     ]
    }
   ],
   "source": [
    "# Degrees/lambda for each split of the dataset\n",
    "degrees = [10, 12, 10, 10]\n",
    "lambdas = [0.0001, 0.003, 0.003, 0.001]\n",
    "\n",
    "# Creation of vector that will contain the predictions of the different splits\n",
    "y_pred = np.zeros(len(y_test))\n",
    "\n",
    "# Go over each split\n",
    "for idx in range(len(masks_jet_train)):\n",
    "\n",
    "    # Get split\n",
    "    tx_train_selected_jet = tx_train[masks_jet_train[idx]]\n",
    "    tx_test_selected_jet = tx_test[masks_jet_test[idx]]\n",
    "    y_train_selected_jet = y_train[masks_jet_train[idx]]\n",
    "\n",
    "    # Remove columns full of NaN\n",
    "    tx_train_selected_jet = tx_train_selected_jet[:, ~np.all(np.isnan(tx_train_selected_jet), axis=0)]\n",
    "    tx_test_selected_jet = tx_test_selected_jet[:, ~np.all(np.isnan(tx_test_selected_jet), axis=0)]\n",
    "\n",
    "    # Remove columns without standard deviation at all\n",
    "    tx_train_selected_jet = tx_train_selected_jet[:, np.nanstd(tx_train_selected_jet, axis=0) != 0]\n",
    "    tx_test_selected_jet = tx_test_selected_jet[:, np.nanstd(tx_test_selected_jet, axis=0) != 0]\n",
    "    \n",
    "    # Replace remaining NaN by median\n",
    "    tx_train_selected_jet = replace_nan_by_median(tx_train_selected_jet)\n",
    "    tx_test_selected_jet = replace_nan_by_median(tx_test_selected_jet)\n",
    "\n",
    "    # Standardize features\n",
    "    mean_train_selected_jet, std_train_selected_jet, tx_train_selected_jet = standardize(tx_train_selected_jet)\n",
    "    tx_test_selected_jet = standardize_predef(tx_test_selected_jet, mean_train_selected_jet, std_train_selected_jet)\n",
    "\n",
    "    # Build poly\n",
    "    tx_train_poly_selected_jet = build_poly_tx(tx_train_selected_jet, degrees[idx])\n",
    "    tx_test_poly_selected_jet = build_poly_tx(tx_test_selected_jet, degrees[idx])\n",
    "    \n",
    "    # Compute best method\n",
    "    w_selected_jet, _ = ridge_regression(y_train_selected_jet, tx_train_poly_selected_jet, lambdas[idx])\n",
    "\n",
    "    # Compute accuracy (only used for printing)\n",
    "    acc = accuracy(y_train_selected_jet, tx_train_poly_selected_jet, w_selected_jet, LOWER_BOUND, UPPER_BOUND)\n",
    "    print(\"Accuracy of split %d:\" % idx, acc)\n",
    "\n",
    "    # pred of split + add it to the final pred\n",
    "    y_test_pred = predict_labels(w_selected_jet, tx_test_poly_selected_jet, LOWER_BOUND, UPPER_BOUND)\n",
    "    y_pred[masks_jet_test[idx]] = y_test_pred.flatten()\n",
    "\n",
    "print(\"Number of %d:\" % UPPER_BOUND, np.count_nonzero(y_pred == UPPER_BOUND))\n",
    "print(\"Number of %d:\" % LOWER_BOUND, np.count_nonzero(y_pred == LOWER_BOUND))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_test, y_pred, \"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test n : algorithm / features / y / w\n",
    "- - - - - - - - - - - - - - - - - - - \n",
    "Test 1 : least_squares / all features standardized / y = -1,1 / random init_w\n",
    "\n",
    "Test 2 : least_squares / corr > 0.1 features standardized / y = -1,1 / random init_w\n",
    "\n",
    "Test 3 : least_squares_GD(10000,0.5) / all features standardized / y = -1,1 / random init_w\n",
    "\n",
    "Test 4 : least_squares_GD(10000,0.5) / all features standardized / y = -1,1 / random init_w / poly, degree=1\n",
    "\n",
    "Test 5 : least_squares / all features standardized / y = -1,1 / random init_w / median + categorical\n",
    "\n",
    "Test 6 : logistic_regressoin  /all features standardized / y = 0,1 / random init_w / median + categorical + balanced\n",
    "\n",
    "Test 7 : least_squares / all features standardized / y = 0,1 / random init_w\n",
    "\n",
    "Test 8 : Test 1\n",
    "\n",
    "Test 9 : Test 1\n",
    "\n",
    "Test 10 : Test 1 / standardized test_set with mean and std from train_set\n",
    "\n",
    "Test 11 : Test 1 / standardized test_set with mean and std from train_set / balance\n",
    "\n",
    "Test 12 : Ridge regression / non-balanced / standardized test_set with mean and std from train_set / y=-1,1 / mean of 4 best lambdas for degree 11\n",
    "\n",
    "Test 13 : Ridge regression / balanced / standardized test_set with mean and std from train_set / y=-1,1 / mean of 4 best lambdas for degree 11\n",
    "\n",
    "Test 14 : Ridge regression / balanced before doing anything / standardized test_set with mean and std from train_set / y=-1,1 / mean of 4 best lambdas for degree 11\n",
    "\n",
    "Test 15 : Ridge regression / Removed all rows containing at least a NaN / balanced before doing anything / standardized test_set with mean and std from train_set / y=-1,1 / mean of 4 best lambdas for degree 11 / Replaced NaN values in test_set by median in test_set\n",
    "\n",
    "Test 16 : balanced before doing anything / standardized test_set with mean and std from train_set / y=-1,1 / Ensembling with: (\"least_squares_GD\", 1, 150, 0, 0.01, 0), (\"least_squares_GD\", 1, 50, 0, 0.25, 0), (\"least_squares_SGD\", 1, 30, 256, 0.2, 0), (\"least_squares_SGD\", 1, 60, 64, 0.1, 0), (\"ridge_regression\", 7, 0, 0, 0, 0.001), (\"ridge_regression\", 9, 0, 0, 0, 0.001), (\"ridge_regression\", 11, 0, 0, 0, 0.001)\n",
    "\n",
    "Test 17 : balanced before doing anything / standardized test_set with mean and std from train_set / y=-1,1 / Separating into 4 models based on feature 22, using Ridge everytime with degrees = [9, 11, 11, 11] and lambdas = [0.00046415888336127773, 0.001291549665014884, 4.6415888336127818e-05, 1.0000000000000001e-05]\n",
    "\n",
    "Test 18 : non-balanced / standardized test_set with mean and std from train_set / y=-1,1 / Separating into 4 models based on feature 22, using Ridge everytime with degrees = [9, 12, 12, 11] and lambdas = [4.6415888336127818e-05, 0.001, 0.0021544346900318821, 2.1544346900318823e-05]\n",
    "\n",
    "Test 19 : non-balanced / standardized test_set with mean and std from train_set BUT AFTER SEPARATING / y=-1,1 / Separating into 4 models based on feature 22, using Ridge everytime with degrees = [8, 12, 12, 11] and lambdas = [2.1544346900318823e-05, 0.0021544346900318821, 0.00046415888336127773, 0.0001]\n",
    "\n",
    "Test 20 : balanced / standardized test_set with mean and std from train_set BUT AFTER SEPARATING / y=-1,1 / Separating into 4 models based on feature 22, using Ridge everytime with degrees = [8, 13, 12, 10] and lambdas = [0.001, 0.001, 0.0021544346900318821, 0.001]\n",
    "\n",
    "Test 21 : non-balanced / standardized test_set with mean and std from train_set BUT AFTER SEPARATING / y=-1,1 / Separating into 3 models based on feature 22, using Ridge everytime with degrees = [8, 12, 12] and lambdas = [2.1544346900318823e-05, 0.0021544346900318821, 0.00046415888336127773]\n",
    "\n",
    "Test 22 : non-balanced / standardized test_set with mean and std from train_set BUT AFTER SEPARATING / y=-1,1 / Separating into 3 models based on feature 22, using Ridge everytime with degrees = [9, 12, 10] and lambdas = [4.6415888336127818e-05, 0.0021544346900318821, 0.00046415888336127773] / New features being inverse log\n",
    "\n",
    "Test 23 : non-balanced / standardized test_set with mean and std from train_set / y=-1,1 / Separating into 3 models based on feature 22, using Ridge everytime with degrees = [10, 12, 10] and lambdas = [0.00021544346900318823, 0.00046415888336127773, 0.001] / New features being inverse log\n",
    "\n",
    "Test 24 : non-balanced / standardized test_set with mean and std from train_set / y=-1,1 / Separating into 4 models based on feature 22, using Ridge everytime with degrees = [10, 12, 9, 10] and lambdas = [0.00021544346900318823, 0.00046415888336127773, 1.0000000000000001e-05, 0.001] / New features being inverse log\n",
    "\n",
    "Test 25 : balanced / standardized test_set with mean and std from train_set / y=-1,1 / Separating into 4 models based on feature 22, using Ridge everytime with degrees = [11, 11, 10, 9] and lambdas = [0.0001, 3.1622776601683795e-05, 0.00031622776601683794, 0.01] / New features being inverse log\n",
    "\n",
    "Test 26 : non-balanced / standardized test_set with mean and std from train_set BUT AFTER SEPARATING / y=-1,1 / Separating into 3 models based on feature 22, using Ridge everytime (unknown degrees and lambdas) / New features being inverse log\n",
    "\n",
    "Test 27 : non-balanced / standardized test_set with mean and std from train_set / y=-1,1 / Separating into 4 models based on feature 22, using Ridge everytime with degrees = [10, 12, 10, 10] and lambdas = [0.00021544346900318823, 0.0031622776601683794, 0.0031622776601683794, 0.001] / New features being inverse log\n",
    "\n",
    "Test 28 : non-balanced / standardized test_set with mean and std from train_set / y=-1,1 / Separating into 4 models based on feature 22, using Ridge everytime with degrees = [10, 12, 10, 10] and lambdas = [0.0001, 0.0031622776601683794, 0.001, 0.001] / New features being inverse log + pseudorapidity (eta)\n",
    "\n",
    "Test 29 : non-balanced / standardized test_set with mean and std from train_set BUT AFTER SEPARATING / y=-1,1 / Separating into 4 models based on feature 22, using Ridge everytime with degrees = [10, 12, 10, 10] and lambdas = [0.0002, 0.003, 0.003, 0.001] / New features being inverse log\n",
    "\n",
    "Test 30 : Test 26 with degrees = [11, 12, 10, 10] and lambdas = [0.00003, 0.003, 0.003, 0.001]\n",
    "\n",
    "Test 31 : Test 26 with degrees = [10, 12, 10, 10] and lambdas = [0.0001, 0.003, 0.003, 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
